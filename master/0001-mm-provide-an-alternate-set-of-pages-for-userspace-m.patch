From b41c5fa3419525d6f39eacb58b2378900d640829 Mon Sep 17 00:00:00 2001
From: Jenny Herbert <jennifer.herbert@citrix.com>
Date: Thu, 18 Dec 2014 14:48:15 +0000
Subject: [PATCH 1/4] mm: provide an alternate set of pages for userspace
 mappings

Add an option array of pages to struct vm_area_struct that can be used
find the page backing a VMA.  This is useful in cases where the normal
mechanisms for finding the page don't work.

One use case is a Xen PV guest mapping foreign pages into userspace.  The
PTEs contain MFNs which must be translated to PFNs to lookup the page.
For foreign pages (those owned by another guest) the M2P lookup returns
the PFN as seen by the foreign guest (which would be completely the wrong
page for the local guest).

diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h
index 10a9a17..eb9e7d6 100644
--- a/include/linux/mm_types.h
+++ b/include/linux/mm_types.h
@@ -289,6 +289,14 @@ struct vm_area_struct {
 #ifdef CONFIG_NUMA
 	struct mempolicy *vm_policy;	/* NUMA policy for the VMA */
 #endif
+	/*
+	 * Array of pages to override the default vm_normal_page()
+	 * result iff the PTE is special.
+	 *
+	 * The memory for this should be refcounted in vm_ops->open
+	 * and vm_ops->close.
+	 */
+	struct page **pages;
 };
 
 struct core_thread {
diff --git a/mm/memory.c b/mm/memory.c
index 4b60011..3ca13bb 100644
--- a/mm/memory.c
+++ b/mm/memory.c
@@ -774,6 +774,8 @@ struct page *vm_normal_page(struct vm_area_struct *vma, unsigned long addr,
 	if (HAVE_PTE_SPECIAL) {
 		if (likely(!pte_special(pte)))
 			goto check_pfn;
+		if (vma->pages)
+			return vma->pages[(addr - vma->vm_start) >> PAGE_SHIFT];
 		if (vma->vm_flags & (VM_PFNMAP | VM_MIXEDMAP))
 			return NULL;
 		if (!is_zero_pfn(pfn))
diff --git a/mm/mmap.c b/mm/mmap.c
index 8f87b14..fe747d0 100644
--- a/mm/mmap.c
+++ b/mm/mmap.c
@@ -2408,6 +2408,7 @@ static int __split_vma(struct mm_struct * mm, struct vm_area_struct * vma,
 {
 	struct mempolicy *pol;
 	struct vm_area_struct *new;
+	unsigned long delta;
 	int err = -ENOMEM;
 
 	if (is_vm_hugetlb_page(vma) && (addr &
@@ -2423,11 +2424,20 @@ static int __split_vma(struct mm_struct * mm, struct vm_area_struct * vma,
 
 	INIT_LIST_HEAD(&new->anon_vma_chain);
 
+	delta = (addr - vma->vm_start) >> PAGE_SHIFT;
+
 	if (new_below)
 		new->vm_end = addr;
 	else {
 		new->vm_start = addr;
-		new->vm_pgoff += ((addr - vma->vm_start) >> PAGE_SHIFT);
+		new->vm_pgoff += delta;
+	}
+
+	if (vma->pages) {
+		if (new_below)
+			vma->pages += delta;
+		else
+			new->pages += delta;
 	}
 
 	pol = mpol_dup(vma_policy(vma));
