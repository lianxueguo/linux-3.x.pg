From: Zoltan Kiss <zoltan.kiss@citrix.com>
To: Wei Liu <wei.liu2@citrix.com>
To: Ian Campbell <Ian.Campbell@citrix.com>
Subject: [PATCH] xen-netback: Turn off the carrier if the guest is not able to receive

Currently when the guest is not able to receive more packets, qdisc layer starts
a timer, and when it goes off, qdisc is started again to deliver a packet again.
This is a very slow way to drain the queues, consumes unnecessary resources and
slows down other guests shutdown.
This patch change the behaviour by turning the carrier off when that timer
fires, so all the packets are freed up which were stucked waiting for that vif.
Instead of the rx_queue_purge bool it uses the VIF_STATUS_RX_PURGE_EVENT bit to
signal the thread that either the timeout happened or an RX interrupt arrived,
so the thread can check what it should do. It also disables NAPI, so the guest
can't transmit, but leaves the interrupts on, so it can resurrect.

Signed-off-by: Zoltan Kiss <zoltan.kiss@citrix.com>
Signed-off-by: David Vrabel <david.vrabel@citrix.com>
Cc: netdev@vger.kernel.org
Cc: linux-kernel@vger.kernel.org
Cc: xen-devel@lists.xenproject.org 
diff --git a/drivers/net/xen-netback/common.h b/drivers/net/xen-netback/common.h
index 72d0c3d..b7e5a06 100644
--- a/drivers/net/xen-netback/common.h
+++ b/drivers/net/xen-netback/common.h
@@ -102,7 +102,11 @@ struct xenvif_rx_meta {
 
 enum state_bit_shift {
 	/* This bit marks that the vif is connected */
-	VIF_STATUS_CONNECTED
+	VIF_STATUS_CONNECTED,
+	/* This bit signals the RX thread that queuing was stopped (in
+	 * start_xmit), and either the timer fired or an RX interrupt came
+	 */
+	VIF_STATUS_RX_PURGE_EVENT
 };
 
 struct xenvif {
@@ -161,9 +165,8 @@ struct xenvif {
 	struct xen_netif_rx_back_ring rx;
 	struct sk_buff_head rx_queue;
 	RING_IDX rx_last_skb_slots;
-	bool rx_queue_purge;
 
-	struct timer_list wake_queue;
+	struct timer_list rx_stalled;
 
 	/* This array is allocated seperately as it is large */
 	struct gnttab_copy *grant_copy_op;
diff --git a/drivers/net/xen-netback/interface.c b/drivers/net/xen-netback/interface.c
index d114ee8..bddecf1 100644
--- a/drivers/net/xen-netback/interface.c
+++ b/drivers/net/xen-netback/interface.c
@@ -67,8 +67,12 @@ static int xenvif_poll(struct napi_struct *napi, int budget)
 	/* This vif is rogue, we pretend we've there is nothing to do
 	 * for this vif to deschedule it from NAPI. But this interface
 	 * will be turned off in thread context later.
+	 * Also, if a guest doesn't post enough slots to receive data on one of
+	 * its queues, the carrier goes down and NAPI is descheduled here so
+	 * the guest can't send more packets until it's ready to receive.
 	 */
-	if (unlikely(vif->disabled)) {
+	if (unlikely(vif->disabled ||
+		     !netif_carrier_ok(vif->dev))) {
 		napi_complete(napi);
 		return 0;
 	}
@@ -87,6 +91,8 @@ static irqreturn_t xenvif_rx_interrupt(int irq, void *dev_id)
 {
 	struct xenvif *vif = dev_id;
 
+	if (unlikely(netif_queue_stopped(vif->dev) || !netif_carrier_ok(vif->dev)))
+		set_bit(VIF_STATUS_RX_PURGE_EVENT, &vif->status);
 	xenvif_kick_thread(vif);
 
 	return IRQ_HANDLED;
@@ -100,15 +106,13 @@ irqreturn_t xenvif_interrupt(int irq, void *dev_id)
 	return IRQ_HANDLED;
 }
 
-static void xenvif_wake_queue(unsigned long data)
+static void xenvif_rx_stalled(unsigned long data)
 {
 	struct xenvif *vif = (struct xenvif *)data;
 
 	if (netif_queue_stopped(vif->dev)) {
-		netdev_err(vif->dev, "draining TX queue\n");
-		vif->rx_queue_purge = true;
+		set_bit(VIF_STATUS_RX_PURGE_EVENT, &vif->status);
 		xenvif_kick_thread(vif);
-		netif_wake_queue(vif->dev);
 	}
 }
 
@@ -141,10 +145,10 @@ static int xenvif_start_xmit(struct sk_buff *skb, struct net_device *dev)
 	 * drain.
 	 */
 	if (!xenvif_rx_ring_slots_available(vif, min_slots_needed)) {
-		vif->wake_queue.function = xenvif_wake_queue;
-		vif->wake_queue.data = (unsigned long)vif;
+		vif->rx_stalled.function = xenvif_rx_stalled;
+		vif->rx_stalled.data = (unsigned long)vif;
 		xenvif_stop_queue(vif);
-		mod_timer(&vif->wake_queue,
+		mod_timer(&vif->rx_stalled,
 			jiffies + rx_drain_timeout_jiffies);
 	}
 
@@ -356,7 +360,7 @@ struct xenvif *xenvif_alloc(struct device *parent, domid_t domid,
 	init_timer(&vif->credit_timeout);
 	vif->credit_window_start = get_jiffies_64();
 
-	init_timer(&vif->wake_queue);
+	init_timer(&vif->rx_stalled);
 
 	dev->netdev_ops	= &xenvif_netdev_ops;
 	dev->hw_features = NETIF_F_SG |
@@ -538,7 +542,7 @@ void xenvif_disconnect(struct xenvif *vif)
 	xenvif_carrier_off(vif);
 
 	if (vif->task) {
-		del_timer_sync(&vif->wake_queue);
+		del_timer_sync(&vif->rx_stalled);
 		kthread_stop(vif->task);
 		vif->task = NULL;
 	}
@@ -567,16 +571,12 @@ void xenvif_free(struct xenvif *vif)
 	/* Here we want to avoid timeout messages if an skb can be legitimately
 	 * stuck somewhere else. Realistically this could be an another vif's
 	 * internal or QDisc queue. That another vif also has this
-	 * rx_drain_timeout_msecs timeout, but the timer only ditches the
-	 * internal queue. After that, the QDisc queue can put in worst case
-	 * XEN_NETIF_RX_RING_SIZE / MAX_SKB_FRAGS skbs into that another vif's
-	 * internal queue, so we need several rounds of such timeouts until we
-	 * can be sure that no another vif should have skb's from us. We are
-	 * not sending more skb's, so newly stuck packets are not interesting
-	 * for us here.
+	 * rx_drain_timeout_msecs timeout, so give it time to drain out.
+	 * Although if that other guest wakes up just before its timeout happens
+	 * and takes only one skb from QDisc, it can hold onto other skbs for a
+	 * longer period.
 	 */
-	unsigned int worst_case_skb_lifetime = (rx_drain_timeout_msecs/1000) *
-		DIV_ROUND_UP(XENVIF_QUEUE_LENGTH, (XEN_NETIF_RX_RING_SIZE / MAX_SKB_FRAGS));
+	unsigned int worst_case_skb_lifetime = (rx_drain_timeout_msecs/1000);
 
 	for (i = 0; i < MAX_PENDING_REQS; ++i) {
 		if (vif->grant_tx_handle[i] != NETBACK_INVALID_HANDLE) {
diff --git a/drivers/net/xen-netback/netback.c b/drivers/net/xen-netback/netback.c
index f91ba78..ed96117 100644
--- a/drivers/net/xen-netback/netback.c
+++ b/drivers/net/xen-netback/netback.c
@@ -1854,9 +1854,8 @@ void xenvif_idx_unmap(struct xenvif *vif, u16 pending_idx)
 
 static inline int rx_work_todo(struct xenvif *vif)
 {
-	return (!skb_queue_empty(&vif->rx_queue) &&
-	       xenvif_rx_ring_slots_available(vif, vif->rx_last_skb_slots)) ||
-	       vif->rx_queue_purge;
+	return !skb_queue_empty(&vif->rx_queue) &&
+		xenvif_rx_ring_slots_available(vif, vif->rx_last_skb_slots);
 }
 
 static inline int tx_work_todo(struct xenvif *vif)
@@ -1930,6 +1929,54 @@ static void xenvif_start_queue(struct xenvif *vif)
 		netif_wake_queue(vif->dev);
 }
 
+/* Only called from the queue's thread, it handles the situation when the guest
+ * doesn't post enough requests on the receiving ring.
+ * First xenvif_start_xmit disables QDisc and start a timer, and then either the
+ * timer fires, or the guest send an interrupt after posting new request. If it
+ * is the timer, the carrier is turned off here.
+ * */
+static void xenvif_rx_purge_event(struct xenvif *vif)
+{
+	/* Either the last unsuccesful skb or at least 1 slot should fit */
+	int needed = vif->rx_last_skb_slots ?
+		     vif->rx_last_skb_slots : 1;
+
+	if (!xenvif_rx_ring_slots_available(vif, needed)) {
+		/* It is assumed that if the guest post new slots after this,
+		 * the RX interrupt will set the VIF_STATUS_RX_PURGE_EVENT bit
+		 * and wake up the thread again
+		 */
+		rtnl_lock();
+		if (netif_carrier_ok(vif->dev)) {
+			/* Timer fired and there are still no slots. Turn off
+			 * everything except the interrupts
+			 */
+			netif_carrier_off(vif->dev);
+			skb_queue_purge(&vif->rx_queue);
+			vif->rx_last_skb_slots = 0;
+			if (net_ratelimit())
+				netdev_err(vif->dev, "Carrier off due to lack of guest response\n");
+		}
+		rtnl_unlock();
+	} else if (!netif_carrier_ok(vif->dev)) {
+		/* The carrier was down, but an interrupt kicked the thread
+		 * again after new requests were posted
+		 */
+		rtnl_lock();
+		netif_carrier_on(vif->dev);
+		xenvif_start_queue(vif);
+		rtnl_unlock();
+		napi_schedule(&vif->napi);
+		if (net_ratelimit())
+			netdev_err(vif->dev, "Carrier on again\n");
+		continue;
+	} else {
+		/* Queuing were stopped, but the guest posted new requests */
+		del_timer_sync(&vif->rx_stalled);
+		xenvif_start_queue(vif);
+		continue;
+	}
+}
 int xenvif_kthread_guest_rx(void *data)
 {
 	struct xenvif *vif = data;
@@ -1939,6 +1986,7 @@ int xenvif_kthread_guest_rx(void *data)
 		wait_event_interruptible(vif->wq,
 					 rx_work_todo(vif) ||
 					 vif->disabled ||
+					 test_bit(VIF_STATUS_RX_PURGE_EVENT, &vif->status) ||
 					 kthread_should_stop());
 
 		/* This frontend is found to be rogue, disable it in
@@ -1949,24 +1997,16 @@ int xenvif_kthread_guest_rx(void *data)
 		 */
 		if (unlikely(vif->disabled))
 			xenvif_carrier_off(vif);
+		else if (unlikely(test_and_clear_bit(VIF_STATUS_RX_PURGE_EVENT,
+						     &vif->status)))
+			xenvif_rx_purge_event(vif);
 
 		if (kthread_should_stop())
 			break;
 
-		if (vif->rx_queue_purge) {
-			skb_queue_purge(&vif->rx_queue);
-			vif->rx_queue_purge = false;
-		}
-
 		if (!skb_queue_empty(&vif->rx_queue))
 			xenvif_rx_action(vif);
 
-		if (skb_queue_empty(&vif->rx_queue) &&
-		    netif_queue_stopped(vif->dev)) {
-			del_timer_sync(&vif->wake_queue);
-			xenvif_start_queue(vif);
-		}
-
 		cond_resched();
 	}
 
