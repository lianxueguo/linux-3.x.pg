From: Wei Liu <wei.liu2@citrix.com>
To: <xen-devel@lists.xen.org>, <netdev@vger.kernel.org>
CC: <ian.campbell@citrix.com>, <zoltan.kiss@citrix.com>,
	<david.vrabel@citrix.com>, Wei Liu <wei.liu2@citrix.com>
Subject: [PATCH net v4 2/3] xen-netback: don't stop dealloc kthread too early

Reference count the number of packets in host stack, so that we don't
stop the deallocation thread too early. If not, we can end up with
xenvif_free permanently waiting for deallocation thread to unmap grefs.

Reported-by: Thomas Leonard <talex5@gmail.com>
Signed-off-by: Wei Liu <wei.liu2@citrix.com>
Cc: Ian Campbell <ian.campbell@citrix.com>
Cc: Zoltan Kiss <zoltan.kiss@citrix.com>
---
diff --git a/drivers/net/xen-netback/common.h b/drivers/net/xen-netback/common.h
index b7e5a06..01107fe 100644
--- a/drivers/net/xen-netback/common.h
+++ b/drivers/net/xen-netback/common.h
@@ -154,6 +154,7 @@ struct xenvif {
 	u16 dealloc_ring[MAX_PENDING_REQS];
 	struct task_struct *dealloc_task;
 	wait_queue_head_t dealloc_wq;
+	atomic_t inflight_packets;
 
 	/* Use kthread for guest RX */
 	struct task_struct *task;
@@ -285,4 +286,7 @@ extern unsigned int rx_drain_timeout_jiffies;
 extern struct dentry *xen_netback_dbg_root;
 #endif
 
+void xenvif_skb_zerocopy_prepare(struct xenvif *vif, struct sk_buff *skb);
+void xenvif_skb_zerocopy_complete(struct xenvif *vif);
+
 #endif /* __XEN_NETBACK__COMMON_H__ */
diff --git a/drivers/net/xen-netback/interface.c b/drivers/net/xen-netback/interface.c
index b42fef2..3ca9f5a 100644
--- a/drivers/net/xen-netback/interface.c
+++ b/drivers/net/xen-netback/interface.c
@@ -43,6 +43,22 @@
 #define XENVIF_QUEUE_LENGTH 32
 #define XENVIF_NAPI_WEIGHT  64
 
+/* This function is used to set SKBTX_DEV_ZEROCOPY as well as
+ * increasing the inflight counter. We need to increase the inflight
+ * counter because core driver calls into xenvif_zerocopy_callback
+ * which calls xenvif_skb_zerocopy_complete.
+ */
+void xenvif_skb_zerocopy_prepare(struct xenvif *vif, struct sk_buff *skb)
+{
+	skb_shinfo(skb)->tx_flags |= SKBTX_DEV_ZEROCOPY;
+	atomic_inc(&vif->inflight_packets);
+}
+
+void xenvif_skb_zerocopy_complete(struct xenvif *vif)
+{
+	atomic_dec(&vif->inflight_packets);
+}
+
 int xenvif_schedulable(struct xenvif *vif)
 {
 	return netif_running(vif->dev) &&
@@ -438,6 +454,8 @@ int xenvif_connect(struct xenvif *vif, unsigned long tx_ring_ref,
 	init_waitqueue_head(&vif->wq);
 	init_waitqueue_head(&vif->dealloc_wq);
 
+	atomic_set(&vif->inflight_packets, 0);
+
 	if (tx_evtchn == rx_evtchn) {
 		/* feature-split-event-channels == 0 */
 		err = bind_interdomain_evtchn_to_irqhandler(
diff --git a/drivers/net/xen-netback/netback.c b/drivers/net/xen-netback/netback.c
index ee19034..f52a756 100644
--- a/drivers/net/xen-netback/netback.c
+++ b/drivers/net/xen-netback/netback.c
@@ -1515,10 +1515,12 @@ static int xenvif_handle_frag_list(struct xenvif *vif, struct sk_buff *skb)
 	/* remove traces of mapped pages and frag_list */
 	skb_frag_list_init(skb);
 	uarg = skb_shinfo(skb)->destructor_arg;
+	/* increase inflight counter to offset decrement in callback */
+	atomic_inc(&vif->inflight_packets);
 	uarg->callback(uarg, true);
 	skb_shinfo(skb)->destructor_arg = NULL;
 
-	skb_shinfo(nskb)->tx_flags |= SKBTX_DEV_ZEROCOPY;
+	xenvif_skb_zerocopy_prepare(vif, nskb);
 	kfree_skb(nskb);
 
 	return 0;
@@ -1579,7 +1581,7 @@ static int xenvif_tx_submit(struct xenvif *vif)
 				if (net_ratelimit())
 					netdev_err(vif->dev,
 						   "Not enough memory to consolidate frag_list!\n");
-				skb_shinfo(skb)->tx_flags |= SKBTX_DEV_ZEROCOPY;
+				xenvif_skb_zerocopy_prepare(vif, skb);
 				kfree_skb(skb);
 				continue;
 			}
@@ -1599,7 +1601,7 @@ static int xenvif_tx_submit(struct xenvif *vif)
 				   "Can't setup checksum in net_tx_action\n");
 			/* We have to set this flag to trigger the callback */
 			if (skb_shinfo(skb)->destructor_arg)
-				skb_shinfo(skb)->tx_flags |= SKBTX_DEV_ZEROCOPY;
+				xenvif_skb_zerocopy_prepare(vif, skb);
 			kfree_skb(skb);
 			continue;
 		}
@@ -1631,7 +1633,7 @@ static int xenvif_tx_submit(struct xenvif *vif)
 		 * skb. E.g. the __pskb_pull_tail earlier can do such thing.
 		 */
 		if (skb_shinfo(skb)->destructor_arg) {
-			skb_shinfo(skb)->tx_flags |= SKBTX_DEV_ZEROCOPY;
+			xenvif_skb_zerocopy_prepare(vif, skb);
 			vif->tx_zerocopy_sent++;
 		}
 
@@ -1671,6 +1673,8 @@ void xenvif_zerocopy_callback(struct ubuf_info *ubuf, bool zerocopy_success)
 		vif->tx_zerocopy_success++;
 	else
 		vif->tx_zerocopy_fail++;
+
+	xenvif_skb_zerocopy_complete(vif);
 }
 
 static inline void xenvif_tx_dealloc_action(struct xenvif *vif)
@@ -2019,15 +2023,24 @@ int xenvif_kthread_guest_rx(void *data)
 	return 0;
 }
 
+static bool xenvif_dealloc_kthread_should_stop(struct xenvif *vif)
+{
+	/* Dealloc thread must remain running until all inflight
+	 * packets complete.
+	 */
+	return kthread_should_stop() &&
+		!atomic_read(&vif->inflight_packets);
+}
+
 int xenvif_dealloc_kthread(void *data)
 {
 	struct xenvif *vif = data;
 
-	while (!kthread_should_stop()) {
+	for (;;) {
 		wait_event_interruptible(vif->dealloc_wq,
 					 tx_dealloc_work_todo(vif) ||
-					 kthread_should_stop());
-		if (kthread_should_stop())
+					 xenvif_dealloc_kthread_should_stop(vif));
+		if (xenvif_dealloc_kthread_should_stop(vif))
 			break;
 
 		xenvif_tx_dealloc_action(vif);
